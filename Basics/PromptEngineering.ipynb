{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from constants import openai_key\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "# print(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want you to act as a acting financial advisor for people.\\nIn an easy way, explain the basics of income tax.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "demo_template='''I want you to act as a acting financial advisor for people.\n",
    "In an easy way, explain the basics of {financial_concept}.'''\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    input_variables=['financial_concept'],\n",
    "    template=demo_template\n",
    "    )\n",
    "\n",
    "prompt.format(financial_concept='income tax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (0.1.23)\n",
      "Collecting langchain_openai\n",
      "  Using cached langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain_core in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (0.2.40)\n",
      "Collecting langchain_core\n",
      "  Using cached langchain_core-0.3.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (0.1.120)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (2.9.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain_openai) (1.43.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain_core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain_core) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain_core) (4.12.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.8.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.65.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.10.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.40.0->langchain_openai) (0.4.6)\n",
      "Using cached langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n",
      "Using cached langchain_core-0.3.0-py3-none-any.whl (405 kB)\n",
      "Installing collected packages: langchain_core, langchain_openai\n",
      "  Attempting uninstall: langchain_core\n",
      "    Found existing installation: langchain-core 0.2.40\n",
      "    Uninstalling langchain-core-0.2.40:\n",
      "      Successfully uninstalled langchain-core-0.2.40\n",
      "  Attempting uninstall: langchain_openai\n",
      "    Found existing installation: langchain-openai 0.1.23\n",
      "    Uninstalling langchain-openai-0.1.23:\n",
      "      Successfully uninstalled langchain-openai-0.1.23\n",
      "Successfully installed langchain_core-0.3.0 langchain_openai-0.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-community 0.2.16 requires langchain<0.3.0,>=0.2.16, but you have langchain 0.3.0 which is incompatible.\n",
      "langchain-community 0.2.16 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 0.3.0 which is incompatible.\n",
      "langchain-experimental 0.0.65 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 0.3.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade langchain langchain_openai langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.kumar\\AppData\\Local\\Temp\\ipykernel_13740\\4256826792.py:5: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  chain1=LLMChain(llm=llm,prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm=OpenAI(temperature=0.7)\n",
    "chain1=LLMChain(llm=llm,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'financial_concept': 'GDP',\n",
       " 'text': \"\\n\\nSure, I'd be happy to act as a financial advisor and explain the basics of GDP to you.\\n\\nGDP stands for Gross Domestic Product, and it is a measure of the total economic output of a country. Basically, it measures the total value of all goods and services produced within a country's borders in a specific time period, usually a year.\\n\\nThink of it as a way to measure the size and health of a country's economy. GDP takes into account all the goods and services that are produced, including things like cars, food, clothing, and services like healthcare, education, and banking.\\n\\nIt's important to note that GDP only measures the final value of goods and services, not the individual costs of the inputs that went into producing them. For example, if a car is sold for $20,000, that full amount is counted in GDP, even though the cost of the raw materials and labor that went into making the car may have been less.\\n\\nThere are a few different ways to calculate GDP, but the most common method is the expenditure approach. This means adding up all the spending on goods and services within a country, including consumption by individuals and businesses, government spending, and net exports (exports minus imports).\\n\\nGDP is a key indicator of a\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1.invoke ('GDP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In an easy way translate the following sentence 'How are you' into hindi\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template='''In an easy way translate the following sentence '{sentence}' into {target_language}'''\n",
    "language_prompt = PromptTemplate(\n",
    "    input_variables=[\"sentence\",'target_language'],\n",
    "    template=template,\n",
    ")\n",
    "language_prompt.format(sentence=\"How are you\",target_language='hindi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.kumar\\AppData\\Local\\Temp\\ipykernel_13740\\2099346248.py:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  chain2({'sentence':\"Hello How are you\",'target_language':'hindi'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Hello How are you',\n",
       " 'target_language': 'hindi',\n",
       " 'text': '\\n\\nनमस्ते आप कैसे हो '}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2=LLMChain(llm=llm,prompt=language_prompt)\n",
    "\n",
    "chain2({'sentence':\"Hello How are you\",'target_language':'hindi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate\n",
    "\n",
    "# First, create the list of few shot examples.\n",
    "examples = [\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "]\n",
    "\n",
    "# Next, we specify the template to format the examples we have provided.\n",
    "# We use the `PromptTemplate` class for this.\n",
    "example_formatter_template = \"\"\"Word: {word}\n",
    "Antonym: {antonym}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=example_formatter_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we create the `FewShotPromptTemplate` object.\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    # These are the examples we want to insert into the prompt.\n",
    "    examples=examples,\n",
    "    # This is how we want to format the examples when we insert them into the prompt.\n",
    "    example_prompt=example_prompt,\n",
    "    # The prefix is some text that goes before the examples in the prompt.\n",
    "    # Usually, this consists of intructions.\n",
    "    prefix=\"Give the antonym of every input\\n\",\n",
    "    # The suffix is some text that goes after the examples in the prompt.\n",
    "    # Usually, this is where the user input will go\n",
    "    suffix=\"Word: {input}\\nAntonym: \",\n",
    "    # The input variables are the variables that the overall prompt expects.\n",
    "    input_variables=[\"input\"],\n",
    "    # The example_separator is the string we will use to join the prefix, examples, and suffix together with.\n",
    "    example_separator=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "Word: tall\n",
      "Antonym: short\n",
      "\n",
      "Word: big\n",
      "Antonym: \n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format(input='big'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'big', 'text': 'small'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=LLMChain(llm=llm,prompt=few_shot_prompt)\n",
    "chain({'input':\"big\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
