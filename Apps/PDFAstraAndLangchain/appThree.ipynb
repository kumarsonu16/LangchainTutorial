{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 50 text chunks.\n",
      "\n",
      "QUESTION: \"What is the current GDP?\"\n",
      "ANSWER: \"7 per cent.\"\n",
      "\n",
      "FIRST DOCUMENTS BY RELEVANCE:\n",
      "    [0.8953] \"estimated to be at 7 per cent. It is notable that this is the highest among all \n",
      "the ...\"\n",
      "    [0.8948] \"With the theme of ‘ Vasudhaiva Kutumbakam’ , we are steering an \n",
      "ambitious, people-c ...\"\n",
      "    [0.8942] \"multiplier impact on growth and employment. After the subdued period of \n",
      "the pandemi ...\"\n",
      "    [0.8907] \"February 1, 2023 \n",
      "Hon’ble Speaker,  \n",
      " I present the Budget for 2023-24. This is the  ...\"\n",
      "\n",
      "QUESTION: \"How much the agriculture target will be increased to and what the focus will be\"\n",
      "ANSWER: \"The agriculture target will be increased to 20 lakh crore and the focus will be on animal husbandry, dairy, and fisheries.\"\n",
      "\n",
      "FIRST DOCUMENTS BY RELEVANCE:\n",
      "    [0.9325] \"of Millet Research, Hyderabad  will be supported as the Centre of Excellence \n",
      "for sh ...\"\n",
      "    [0.9205] \"Agriculture Accelerator Fund  \n",
      "17. An Agriculture Accelerator Fund will be set-up to ...\"\n",
      "    [0.9117] \"Kashmir, Ladakh and the North-East. This Budget builds on those efforts.  \n",
      "Agricultu ...\"\n",
      "    [0.9073] \"grant will be provided to one of the IITs for five years.   \n",
      "75. To reduce the cost  ...\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import cassio\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Environment variables (helper function)\n",
    "def get_env_var(key: str, default: str = None) -> str:\n",
    "    value = os.environ.get(key)\n",
    "    if not value and default:\n",
    "        return default\n",
    "    elif not value:\n",
    "        raise ValueError(f\"Environment variable {key} not set\")\n",
    "    return value\n",
    "\n",
    "ASTRA_DB_APPLICATION_TOKEN = get_env_var(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "ASTRA_DB_API_ENDPOINT = get_env_var(\"ASTRA_DB_API_ENDPOINT\")\n",
    "ASTRA_DB_NAMESPACE = get_env_var(\"ASTRA_DB_NAMESPACE\")\n",
    "OPENAI_API_KEY = get_env_var(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the Astra DB connection\n",
    "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=\"7d55f754-6018-46c5-8034-0e271ba1f33f\")\n",
    "\n",
    "# Initialize LLM and embeddings\n",
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Initialize AstraDBVectorStore\n",
    "astra_vector_store = AstraDBVectorStore(\n",
    "    embedding=embedding,\n",
    "    api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "    namespace=ASTRA_DB_NAMESPACE,\n",
    "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
    "    collection_name=\"qa_mini_demo_two\",\n",
    ")\n",
    "\n",
    "# PDF file reading logic\n",
    "def extract_pdf_text(pdf_path: str) -> str:\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        content = page.extract_text()\n",
    "        if content:\n",
    "            text += content\n",
    "    return text\n",
    "\n",
    "raw_text = extract_pdf_text('budget_speech.pdf')\n",
    "\n",
    "# Text splitting for vector indexing\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(raw_text)\n",
    "\n",
    "# Add chunks to the vector store\n",
    "astra_vector_store.add_texts(texts[:50])\n",
    "print(f\"Inserted {len(texts[:50])} text chunks.\")\n",
    "\n",
    "# Vector index setup\n",
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)\n",
    "\n",
    "# Question answering loop\n",
    "def query_loop():\n",
    "    first_question = True\n",
    "    while True:\n",
    "        prompt = \"\\nEnter your question (or type 'quit' to exit): \" if first_question else \"\\nWhat's your next question (or type 'quit' to exit): \"\n",
    "        query_text = input(prompt).strip()\n",
    "\n",
    "        if query_text.lower() == 'quit':\n",
    "            break\n",
    "\n",
    "        if not query_text:\n",
    "            continue\n",
    "\n",
    "        first_question = False\n",
    "\n",
    "        # Query for an answer\n",
    "        print(f\"\\nQUESTION: \\\"{query_text}\\\"\")\n",
    "        answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
    "        print(f\"ANSWER: \\\"{answer}\\\"\\n\")\n",
    "\n",
    "        # Show top 4 relevant documents\n",
    "        print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
    "        for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
    "            print(f\"    [{score:.4f}] \\\"{doc.page_content[:84]} ...\\\"\")\n",
    "\n",
    "# Run the query loop\n",
    "query_loop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
